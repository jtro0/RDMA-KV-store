% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Future improvements}\label{ch:future-improvements} % top level followed by section, subsection


% ----------------------- paths to graphics ------------------------

% change according to folder and file names
\ifpdf
    \graphicspath{{7/figures/PNG/}{7/figures/PDF/}{7/figures/}}
\else
    \graphicspath{{7/figures/EPS/}{7/figures/}}
\fi


% ----------------------- contents from here ------------------------
%
\section{Experimental transport types}
Current transportation types all have advantages and disadvantages.
Reliable transport has advantages being predictable packet behavior.
However, as has been shown in this thesis, connection transports (such as RC) have scalability issues, due to the RNIC caching issues with increasing number of QP's.
Dynamically Connected Transport (DCT) is, currently, an experimental transport type which addresses these issues.
DCT has a connection based design, while only requiring one QP.
This is achieved by dynamically connecting and disconnecting with remote QP's, which would introduce additional latency with short-lived clients, or when dealing with concurrent large number of clients.
However, could have the potential to combine the reliablilty of RC and

\section{Optimizations}
Currently, no optimizations are used to improve performance.
Since this thesis focused on performance across transport types, this needed to remain consistent throughout.
Optimizations, such as those used in HERD, making use of prefetching and inlined data, improve performance significantly.
Other optimizations can be found in Kalia et. al. paper on design guidelines and possible optimizations\cite{kalia2016design}.
These are hardware focused, including batching, reducing the number of PIO and DMA operations.

This thesis has shown the potential of using UD as scalable and high throughput transport type for RDMA KV stores, however this could be improved further.
One improvement is to have multiple groups of clients, each with a single QP.
This has been shown to be effective in ScaleRPC\cite{chen2019scalable}.
Grouping clients reduces RNIC cache contention, by limiting the number of worker threads competing for cache.
However, like with RC and UC, using multiple QP's increases context switching, which harms performance.
ScaleRPC have proposed solutions to this by "warming up" QP's.

\section{Newer hardware}
Performance benchmarks for this thesis have been ran on DAS-5.
DAS-5 is becoming outdated, with the newer DAS-6 being available mid-2021\cite{das6}.
DAS-6 will make use of 100 Gbit/s Infiniband RNIC, near 2x bandwidth compared to DAS-5.

% ---------------------------------------------------------------------------
% ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------