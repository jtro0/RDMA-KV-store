
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
\chapter{Introduction}

% the code below specifies where the figures are stored
%\ifpdf
%    \graphicspath{{1_introduction/figures/PNG/}{1_introduction/figures/PDF/}{1_introduction/figures/}}
%\else
%    \graphicspath{{1_introduction/figures/EPS/}{1_introduction/figures/}}
%\fi

% ----------------------------------------------------------------------
%: ----------------------- introduction content ----------------------- 
% ----------------------------------------------------------------------



%: ----------------------- HELP: latex document organisation
% the commands below help you to subdivide and organise your thesis
%    \chapter{}       = level 1, top level
%    \section{}       = level 2
%    \subsection{}    = level 3
%    \subsubsection{} = level 4
% note that everything after the percentage sign is hidden from output



\section{Context}
Seemingly ever growing tech giants, such as Facebook, Amazon and Google, require fast, reliable and scalable key-value storage (KV-store) to serve product recommendations, user preferences, and advertisements.
A KV-store is a data storage type which aims to store many small values and provides a high throughput and low latency interface.
KV-stores usually offer a simple interface using 3 commands: GET, SET, and DEL. A trivial implementation makes use of a hash-table which matches the hash value of a given key, to the value associated with that key.
Past advancements of KV-stores have focussed on improving these underlying data structures.
For example, Cuckoo and Hopscotch hashing\cite{geambasu2010comet}, have presented an alternative of an improved hash table algorithm.
Nonetheless, with recent developments with RDMA networks, this has become a more attractive direction to improve KV-stores.

Remote direct memory access (RDMA) networks have increasingly become more popular in commercial and academic data centers, due to the increase in availability and decrease in cost for RDMA capable network interface cards (RNICs).
RDMA offers a more direct connection between two machines, by interfacing the memory directly.

% Move to background
Instead of the operating system (OS) handling the incoming and outgoing packets, RNICs implement this in hardware, requiring no additional help from the OS and CPU. This results in lowering the overall latency and CPU overhead.

\section{Problem statement}
Making efficient use of RDMA networks is a difficult task, and requires in-depth knowledge on the hardware constraints present in the RNICs \cite{chen2019scalable}.
Additionally, in a higher level sense, there are design choices to be made.
RDMA networks can handle of various transportation types and so-called verbs, each with their own advantage and disadvantage.
The impact of transportation types on scalability of RDMA KV-store has not been examined.
Previous work has focused on researching verb choices, less on transportation type.
Scalability is an important factor for growing tech giants.
These require a scalable, high throughput and low latency solution, which RDMA could provide.

\section{Research Question}
This paper will explore to what extent RDMA transportation types affect the performance and scalability of KV-store.
For this, this research will answer the following questions:

\begin{itemize}
    \item[\textbf{RQ1}] How scalable are these transportation types?%, compared to traditional TCP?
    This being an important factor for tech giants which make use of RDMA KV-store, and require a system to be scalable and reach multiple clients.
    \item[\textbf{RQ2}] What are the advantages and disadvantages of RDMA transportation types on an KV-store?
    This question aims to apply the already known information on the RDMA transportation types, on a RDMA KV-store specific setting.
    Aiding the design processes of further RDMA KV-store implementation, and possibly related implementations.
\end{itemize}

\section{Research Method}
In this thesis the network performance of KV-store, with varying protocols, will be studied. 
First an understanding of KV-stores is established.
Along with discussing known issues with traditional networking, a relatively new technology, RDMA, will be introduced.
Network performance, in the form of throughput and latency will be measured and used to evaluate RDMA transport types.

A prototype and experimental approach is taken for this thesis:
\begin{itemize}
    \item[\textbf{M1}] A KV-store prototype will be implemented, with a flexible network interfacing, to include both traditional socket and RDMA interfacing.
    This, and all other relevant project files, are open source and can be found on Github\cite{github}.
    \item[\textbf{M2}] To investigate the performance and scalability between the various networking types, a workload realistic\cite{atikoglu2012workload} macro-level benchmark will be designed.
\end{itemize}

With the focus of this thesis being on the network implementation, a trivial KV-store will be used.
This implementation does not offer strong performance and scalability, however these issues are minimized and kept consistent throughout.

All measurements hereafter are recorded on the DAS-5 computing cluster.
This allows for a consistent working environment.

%\section{Thesis Contributions}
%The underlying KV-store structure is based off of the KV-store assessment from Operating Systems course 2020, at the VU.
%Further, the testing python script has been used to confirm the functioning of KV-store.
%The KV-store has been altered and further implemented by myself, as is the network aspect.
%
%Additionally, some RDMA related helper functions have been created by Dr. Trivedi \cite{rdma_example}.
%

\section{Plagiarism Declaration}


\section{Thesis Structure}
Section \ref{ch:background} will provide the necessarily background knowledge of KV-store, linux sockets, and RDMA.
Next, section \ref{ch:design} will go over the design of the KV-store, networking interfacing, and benchmark.
In section \ref{ch:design} this design will be taken and described the implementation in a more technical prospective.
The benchmarking result will be presented and analyzed in section \ref{ch:evaluation}.
Section \ref{ch:related-work} compares findings with that of previously done work.
Future prospects will be given in section \ref{ch:future-improvements}.
Closing off the thesis, section \ref{ch:conclusion} will go over the conclusion and provide recommendations.